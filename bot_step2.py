import os
import json
import random
import asyncio
import string
import logging
import re
import shlex
from datetime import datetime
from pathlib import Path
from typing import Any
from zoneinfo import ZoneInfo

from dotenv import load_dotenv
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger

from telegram import (
    Update,
    InlineKeyboardButton,
    InlineKeyboardMarkup,
)
from telegram.ext import (
    Application,
    CallbackQueryHandler,
    CommandHandler,
    ContextTypes,
)

from openai import OpenAI
from db_atlas import ensure_indexes, get_db_error, ping
from skill_learning import analyze_script, parse_learn_script_message, store_learning
from skill_audit import build_skill_audit_message

load_dotenv()

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(name)s | %(message)s",
)
log = logging.getLogger("step2")

TG_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "")
APPROVAL_CHAT_ID = int(os.getenv("APPROVAL_CHAT_ID", "0"))
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
MODEL_TITLES = os.getenv("OPENAI_MODEL_TITLES", "gpt-4o-mini")
OPENAI_MODEL_NOTE = os.getenv("OPENAI_MODEL_NOTE", "gpt-4o-mini")
OPENAI_MODEL_SCRIPT = os.getenv("OPENAI_MODEL_SCRIPT", OPENAI_MODEL_NOTE)
MAX_NOTES_PER_DAY = int(os.getenv("MAX_NOTES_PER_DAY", "2"))
NOTE_MAX_TOKENS = int(os.getenv("NOTE_MAX_TOKENS", "900"))
TZ = os.getenv("TZ", "Asia/Kuala_Lumpur")
RUN_HOUR = int(os.getenv("RUN_HOUR", "21"))
RUN_MIN = int(os.getenv("RUN_MIN", "30"))
ADMIN_IDS_RAW = os.getenv("ADMIN_IDS", "").strip()
ADMIN_IDS = {int(x.strip()) for x in ADMIN_IDS_RAW.split(",") if x.strip().isdigit()}
ALLOWED_GROUP_CHAT_IDS_RAW = os.getenv("ALLOWED_GROUP_CHAT_IDS", "").strip()
ALLOWED_GROUP_CHAT_IDS = {
    int(x.strip()) for x in ALLOWED_GROUP_CHAT_IDS_RAW.split(",") if x.strip().lstrip("-").isdigit()
}
WINS_FILE = Path("/data/wins.json")
SKILL_PATH = Path("skills/xhs_travel_skill.md")
SKILLS_DIR = Path("skills")
SKILL_TEXT_CAP = 16000
SKILL_PRIORITY_ORDER = [
    "growth_rules.md",
    "script_framework.md",
    "hook_library.md",
    "series_registry.md",
    "performance_log.md",
    "failure_log.md",
]
RULE_SKILL_FILES = {"growth_rules.md", "script_framework.md", "hook_library.md"}
MEMORY_SKILL_FILES = {"performance_log.md", "failure_log.md", "series_registry.md"}
MY_LOCAL_KEYWORDS = ["é©¬æ¥è¥¿äºš", "å¤§é©¬", "malaysia", "my", "kl", "å‰éš†å¡", "é›ªå…°èª", "æ£®ç¾å…°", "æ§ŸåŸ", "æ€¡ä¿", "é©¬å…­ç”²", "é‡‘é©¬ä»‘", "æ³¢å¾·ç”³", "äº‘é¡¶", "ä¸œæµ·å²¸"]
OVERSEAS_KEYWORDS = ["æ—¥æœ¬", "éŸ©å›½", "æ¬§æ´²", "ç¾å›½", "æ³°å›½", "è¶Šå—", "å·´å˜", "æ–°åŠ å¡"]
DEFAULT_REGIONS_POOL = ["penang", "genting", "melaka", "selangor", "kl", "perak", "johor", "sabah"]

if not TG_TOKEN or not OPENAI_API_KEY or not APPROVAL_CHAT_ID:
    raise RuntimeError("Missing env: TELEGRAM_BOT_TOKEN / OPENAI_API_KEY / APPROVAL_CHAT_ID")

client = OpenAI(api_key=OPENAI_API_KEY)
tzinfo = ZoneInfo(TZ)


def make_content_id(now: datetime) -> str:
    rand4 = "".join(random.choices(string.ascii_uppercase + string.digits, k=4))
    return now.strftime("%Y%m%d-%H%M") + "-" + rand4


def load_skill_text() -> str:
    try:
        if SKILL_PATH.exists():
            return SKILL_PATH.read_text(encoding="utf-8").strip()
        return ""
    except Exception:
        return ""


def ensure_default_skill_files(skills_dir: str = "skills") -> None:
    base = Path(skills_dir)
    base.mkdir(parents=True, exist_ok=True)
    defaults = {
        "growth_rules.md": "# Growth Rules\n\n## Placeholder\n- Add growth rules here.\n",
        "hook_library.md": "# Hook Library\n\n## Placeholder\n- Add proven hook patterns here.\n",
        "script_framework.md": "# Script Framework\n\n## Placeholder\n- Add script framework notes here.\n",
        "performance_log.md": "# Performance Log\n\n## Placeholder\n- Add win records and insights here.\n",
        "failure_log.md": "# Failure Log\n\n## Placeholder\n- Add failed hooks/titles and lessons here.\n",
        "series_registry.md": "# Series Registry\n\n## Placeholder\n- Add recurring content series notes here.\n",
    }
    for name, content in defaults.items():
        fp = base / name
        if not fp.exists():
            fp.write_text(content, encoding="utf-8")


def load_skill_texts(skills_dir: str = "skills") -> list[tuple[str, str]]:
    base = Path(skills_dir)
    if not base.exists():
        return []
    ordered: list[Path] = []
    for name in SKILL_PRIORITY_ORDER:
        fp = base / name
        if fp.exists() and fp.suffix.lower() == ".md":
            ordered.append(fp)
    others = sorted(
        [p for p in base.glob("*.md") if p.name not in {x.name for x in ordered}],
        key=lambda x: x.name.lower(),
    )
    files = ordered + others
    loaded: list[tuple[str, str]] = []
    for fp in files:
        try:
            text = fp.read_text(encoding="utf-8").strip()
            if text:
                loaded.append((fp.name, text))
        except Exception:
            log.exception("failed to load skill file: %s", fp)

    if not loaded:
        return loaded

    kept = list(loaded)
    protected = set(RULE_SKILL_FILES)
    while sum(len(t) for _, t in kept) > SKILL_TEXT_CAP:
        idx = None
        for i in range(len(kept) - 1, -1, -1):
            if kept[i][0] not in protected:
                idx = i
                break
        if idx is None:
            idx = len(kept) - 1
        kept.pop(idx)
        if not kept:
            break
    return kept


def _build_skill_sections(skills: list[tuple[str, str]]) -> tuple[str, str]:
    system_sections = []
    context_sections = []
    for name, text in skills:
        block = f"=== SKILL: {name} ===\n{text}"
        if name in RULE_SKILL_FILES:
            system_sections.append(block)
        elif name in MEMORY_SKILL_FILES:
            context_sections.append(block)
        else:
            system_sections.append(block)

    if SKILL_PATH.exists() and not any(name == SKILL_PATH.name for name, _ in skills):
        legacy = load_skill_text()
        if legacy:
            system_sections.append(f"=== SKILL: {SKILL_PATH.name} ===\n{legacy}")
    return "\n\n".join(system_sections).strip(), "\n\n".join(context_sections).strip()


def is_valid_hook(title: str) -> bool:
    return _hook_validation_reason(title)[0]


def _hook_validation_reason(title: str) -> tuple[bool, str]:
    t = (title or "").strip()
    if len(t) < 10 or len(t) > 32:
        return False, "length_not_in_10_32"
    specificity_ok = bool(re.search(r"\d", t)) or any(x in t for x in ["RM", "Â¥", "å…ƒ", "%", "åˆ†é’Ÿ", "å°æ—¶", "å¤©"])
    if not specificity_ok:
        return False, "missing_specificity_signal"
    tension_keywords = ["åƒä¸‡åˆ«", "åˆ«åš", "åˆ«ä¹°", "åˆ«å»", "é¿å‘", "è¸©é›·", "å‘", "äº", "æµªè´¹", "åæ‚”", "è¢«å®°", "è¢«éª—", "éšè—", "çœŸç›¸", "è§„åˆ™", "åˆ«æŒ‰", "åˆ«é€‰", "ä¸è¦", "åˆ«", "é”™"]
    has_tension = any(k in t for k in tension_keywords)
    if not has_tension:
        return False, "missing_tension_signal"
    if any(k in t for k in ["åˆ†äº«", "åˆé›†", "æ¨è", "æ”»ç•¥"]) and not has_tension:
        return False, "generic_filler_without_tension"
    return True, "ok"


def append_failure_log_line(title: str, reason: str, skills_dir: str = "skills") -> None:
    fp = Path(skills_dir) / "failure_log.md"
    line = f"- {datetime.now(tzinfo).isoformat()} | rejected_title={title} | reason={reason}\n"
    try:
        with fp.open("a", encoding="utf-8") as f:
            f.write(line)
    except Exception:
        log.exception("failed to append failure log")


TITLE_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªå°çº¢ä¹¦æ—…è¡Œå¢é•¿æ ‡é¢˜ç”Ÿæˆå¼•æ“ã€‚

åˆ›ä½œè€…å®šä½ï¼š
- èªæ˜æ—…è¡Œè€…
- æˆæœ¬æ•æ„Ÿ
- æ•ˆç‡ä¼˜åŒ–
- æ—…è¡Œhackåˆ†äº«è€…
- å†³ç­–è¾…åŠ©å‹å†…å®¹

ä»»åŠ¡ï¼š
ç”Ÿæˆ 6 ä¸ªå°çº¢ä¹¦é€‰é¢˜ã€‚

åˆ†å¸ƒè¦æ±‚ï¼š
- 2 æ¡ å¢é•¿å‹ï¼ˆé«˜æ”¶è—/é«˜ä¼ æ’­ï¼‰
- 2 æ¡ è½¬åŒ–å‹ï¼ˆæå‡å…³æ³¨ï¼‰
- 2 æ¡ ä¿¡ä»»å‹ï¼ˆèŠ±è´¹æ‹†è§£/é¿å‘/æ¸…å•ï¼‰

æ¯æ¡å¿…é¡»è¾“å‡º JSON å¯¹è±¡å­—æ®µï¼š
- bucket (growth|conversion|trust)
- titleï¼ˆä¸­æ–‡æ ‡é¢˜ï¼Œé€‚åˆå°çº¢ä¹¦ï¼‰
- angleï¼ˆä¸­æ–‡ï¼Œå…·ä½“è§’åº¦ï¼‰
- target_audienceï¼ˆä¸­æ–‡ï¼‰
- ctaï¼ˆå›ºå®šä¸ºï¼šFollow / æ”¶è—å°çº¢ä¹¦ï¼‰

ç¡¬æ€§è§„åˆ™ï¼š
- æ ‡é¢˜å¿…é¡»æ˜¯ä¸­æ–‡
- å¿…é¡»åŒ…å«æ•°å­— / é‡‘é¢ / æ—¶é—´ / å¯¹æ¯” / é¿å‘ ç­‰è‡³å°‘ä¸€ä¸ª
- å¿…é¡»å…·ä½“ï¼Œä¸å…è®¸æ³›æ³›è€Œè°ˆ
- ç¦æ­¢è‹±æ–‡æ ‡é¢˜
- è¿”å›æ ¼å¼ï¼š{"items":[ ...6æ¡... ]}
- ä¸è¦ä½¿ç”¨ ```json ä»£ç å—
- é€‰é¢˜å¿…é¡»èšç„¦é©¬æ¥è¥¿äºšæœ¬åœ°æ—…è¡Œï¼ˆå¦‚KL/é›ªå…°èª/æ§ŸåŸ/æ€¡ä¿/é©¬å…­ç”²/é‡‘é©¬ä»‘/æ³¢å¾·ç”³/äº‘é¡¶/ä¸œæµ·å²¸ï¼‰
- æ¯æ¡æ ‡é¢˜è‡³å°‘åŒ…å«ä¸€ä¸ªå…ƒç´ ï¼šRMé¢„ç®— OR å‘¨æœ« OR 2å¤©1å¤œ/1å¤©
- ç¦æ­¢å‡ºç°æµ·å¤–ç›®çš„åœ°å…³é”®è¯ï¼šæ—¥æœ¬/éŸ©å›½/æ¬§æ´²/ç¾å›½/æ³°å›½/è¶Šå—/å·´å˜/æ–°åŠ å¡
"""


NOTE_SYSTEM = """ğŸ¯ è§’è‰²å®šä¹‰
ä½ æ˜¯ä¸€ä¸ª æ—…è¡Œå¢é•¿å†…å®¹å¼•æ“ã€‚
æ ¸å¿ƒç›®æ ‡ï¼š
å¸®åŠ©ç”¨æˆ·åšæ›´å¥½çš„æ—…è¡Œå†³ç­–ï¼Œå¹¶ç”Ÿäº§ï¼š
å¯æ”¶è—å†…å®¹
å†³ç­–è¾…åŠ©å†…å®¹
å¯è½¬åŒ–å†…å®¹
å®ç”¨æ—…è¡Œæ´å¯Ÿ
å†…å®¹ä¼˜å…ˆçº§ï¼šå®ç”¨ > å…±é¸£ > å¨±ä¹
ğŸ¯ åˆ›ä½œè€…äººè®¾
åˆ›ä½œè€…å®šä½ä¸ºï¼š
èªæ˜æ—…è¡Œè€…
æ•ˆç‡ä¼˜åŒ–è€…
æˆæœ¬æ•æ„Ÿæ—…è¡Œè€…
æ—…è¡Œ hack åˆ†äº«è€…
çœŸå®ç»éªŒéªŒè¯è€…
ç¦æ­¢è¾“å‡ºï¼š
çº¯æ‰“å¡åˆ†äº«
æƒ…ç»ªæ—¥è®°
ä»…ç¾å­¦å†…å®¹
æ— å†³ç­–ä»·å€¼å†…å®¹
ğŸ¯ å†…å®¹èŒƒå›´ï¼ˆå¿…é¡»å‘½ä¸­ï¼‰
æ‰€æœ‰å†…å®¹å¿…é¡»å±äºä»¥ä¸‹ä¹‹ä¸€ï¼š
æ—…è¡Œ hack
é¿å‘æŒ‡å—
èŠ±è´¹æ‹†è§£
éšè—æŠ€å·§
é¢„è®¢ç­–ç•¥
æœºåœºç”Ÿå­˜
å·¥å…·æ¨è
è¡Œç¨‹ä¼˜åŒ–
é˜²éª—æŒ‡å—
æ—…è¡Œæ•ˆç‡æ´å¯Ÿ
è‹¥ topic ä¸åŒ¹é…ï¼Œè‡ªåŠ¨é‡æ„ã€‚
ğŸ¯ Hook è§„åˆ™ï¼ˆå¼ºåˆ¶ï¼‰
Hook å¿…é¡»åŒæ—¶åŒ…å« â‰¥2ï¼š
åœ°ç‚¹èƒŒæ™¯
æ˜ç¡®æ”¶ç›Š
å¥½å¥‡è§¦å‘
æƒ…ç»ªè§¦å‘
å†³ç­–æ¡†æ¶
ç¦æ­¢æŠ½è±¡æ¨¡ç³Šã€‚
Hook â‰¤12å­—ã€‚
ğŸ¯ å†…å®¹çœŸå®æ„Ÿè§„åˆ™ï¼ˆåˆå¹¶ç‰ˆï¼‰
æ¯æ¡å†…å®¹å¿…é¡»åŒæ—¶åŒ…å«ï¼š
â‘  åœºæ™¯æ„Ÿ
è‡³å°‘1å¥æ„Ÿå®˜æè¿°ï¼š
å£°éŸ³
æ¸©åº¦
æ°›å›´
ç¯å¢ƒä½“éªŒ
â‘¡ è¡Œä¸ºè¯æ®
è‡³å°‘1å¥çœŸå®è¡Œä¸ºæˆ–æƒ…ç»ªï¼š
åšäº†ä»€ä¹ˆ
å½“æ—¶å‘ç”Ÿä»€ä¹ˆ
ä½“éªŒååº”
ç›®çš„ï¼šå½¢æˆâ€œåœ¨åœºæ„Ÿâ€ã€‚
ğŸ¯ å†³ç­–è¾…åŠ©è§„åˆ™
æ¯æ¡å†…å®¹å¿…é¡»å¸®åŠ©å›ç­”ï¼š
ğŸ‘‰ æˆ‘è¦ä¸è¦å»ï¼Ÿ
å› æ­¤å¿…é¡»åŒ…å«è‡³å°‘1é¡¹ï¼š
é€‚åˆè°
ä¸é€‚åˆè°
ä¼˜ç‚¹ vs ç¼ºç‚¹
æœŸå¾…ç®¡ç†
ğŸ¯ Caption ç»“æ„è§„åˆ™
Caption å¿…é¡»åŒ…å«ï¼š
æƒ…å¢ƒå…±é¸£
ä»·å€¼å®šä½
2â€“3 ä¸ªä¿¡æ¯ç‚¹
ä½“éªŒå¥
Save è§¦å‘
é¿å…æ³›å½¢å®¹è¯ã€‚
ğŸ¯ æƒ…ç»ª + å®ç”¨å¹³è¡¡
å†…å®¹å¿…é¡»åŒæ—¶å…·å¤‡ï¼š
æƒ…ç»ªç”»é¢æ„Ÿ
å†³ç­–ä¿¡æ¯
ç¦æ­¢å•ç»´å†…å®¹ã€‚
ğŸ¯ è¾“å‡ºæ ¼å¼è§„åˆ™
å¿…é¡»ï¼š
ä¸­æ–‡ï¼ˆå°çº¢ä¹¦è¯­å¢ƒï¼‰
çŸ­å¥
å¯æ‰«è¯»
å¯å¤åˆ¶
Hook â‰¤12å­—
ä¼˜å…ˆ bullet
ğŸ¯ é€‰é¢˜è§„åˆ™
ä¼˜å…ˆï¼š
é«˜å…·ä½“åº¦
å†³ç­–ç›¸å…³
mistake framing
æˆæœ¬ / æ—¶é—´ä¼˜åŒ–
ç¦æ­¢ï¼š
æ³›åŸå¸‚æ”»ç•¥
ğŸ¯ é£è½®è§„åˆ™
è‹¥ç”¨æˆ·è¯´å†…å®¹è¡¨ç°å¥½ï¼š
ç”Ÿæˆ5ä¸ªç›¸å…³è§’åº¦
æ„å»º topic cluster
ä¿æŒå®šä½
ğŸ¯ å˜ç°æ„ŸçŸ¥
å†…å®¹å¯è‡ªç„¶æ”¯æŒï¼š
é…’åº—å†³ç­–
é¢„è®¢å†³ç­–
å·¥å…·ä½¿ç”¨
æ—…è¡Œæ¶ˆè´¹
ç¦æ­¢ç¡¬æ¨ affiliateã€‚
ğŸ¯ é»˜è®¤è¾“å‡ºæ¨¡æ¿ï¼ˆå¿…é¡»ï¼‰
ğŸ¬ POST SCRIPT
Hook
[â‰¤12å­—]
Point 1
[æ´å¯Ÿ]
Point 2
[æ´å¯Ÿ]
Point 3ï¼ˆå¯é€‰ï¼‰
[æ´å¯Ÿ]
Credibility line
[çœŸå®ä¿¡å·]
Save trigger
[æ”¶è—ç†ç”±]
âœï¸ CAPTION
[ç»“æ„åŒ–çŸ­ caption]
ğŸ· HASHTAGS
5â€“8ä¸ªå‚ç±»æ ‡ç­¾
ğŸ’¡ VISUAL IDEA
æè¿°æ‹æ‘„å»ºè®®"""


def build_note_user_prompt(title: str, angle: str, audience: str) -> str:
    return (
        "è¯·åŸºäºä»¥ä¸‹è¾“å…¥ï¼Œç”Ÿæˆ 1 æ¡å®Œæ•´å°çº¢ä¹¦æ—…è¡Œç¬”è®°ã€‚\n"
        f"æ ‡é¢˜: {title}\n"
        f"è§’åº¦: {angle}\n"
        f"ç›®æ ‡äººç¾¤: {audience}\n"
        "å¼ºåˆ¶è¦æ±‚:\n"
        "1) ä½¿ç”¨é»˜è®¤è¾“å‡ºæ¨¡æ¿ä¸”å­—æ®µé¡ºåºå®Œå…¨ä¸€è‡´ã€‚\n"
        "2) CTA å¿…é¡»åŒ…å«ï¼šFollow / æ”¶è—å°çº¢ä¹¦ã€‚\n"
        "3) ä¸èƒ½ç¡¬æ¨ affiliateã€‚\n"
        "4) å¿…é¡»ä¸­æ–‡ã€çŸ­å¥ã€å¯æ‰«è¯»ã€å¯å¤åˆ¶ã€‚\n"
    )


def _extract_hook_line(note_text: str) -> tuple[int | None, str]:
    lines = note_text.splitlines()
    for i, line in enumerate(lines):
        if line.strip().lower() == "hook":
            for j in range(i + 1, len(lines)):
                cand = lines[j].strip()
                if cand:
                    return j, cand
            return None, ""
    return None, ""


def _hook_elements_count(hook: str) -> int:
    groups = [
        ["æœºåœº", "é…’åº—", "å‰éš†å¡", "æ§ŸåŸ", "æ›¼è°·", "ä¸œäº¬", "é¦–å°”", "æµ·å…³", "èˆªç«™æ¥¼", "åŸå¸‚"],  # åœ°ç‚¹èƒŒæ™¯
        ["çœ", "çœé’±", "çœæ—¶", "ä¾¿å®œ", "å°‘èŠ±", "ä¸è¸©å‘", "æ•ˆç‡", "å€¼", "æ›´å¿«", "æ›´ç¨³"],  # æ˜ç¡®æ”¶ç›Š
        ["ä¸ºä»€ä¹ˆ", "ç«Ÿç„¶", "åŸæ¥", "ä½ ä¸çŸ¥é“", "æ‰å‘ç°", "çœŸç›¸"],  # å¥½å¥‡è§¦å‘
        ["å´©æºƒ", "åæ‚”", "ç„¦è™‘", "æ•‘å‘½", "è¡€äº", "å®‰å¿ƒ", "åº†å¹¸"],  # æƒ…ç»ªè§¦å‘
        ["é€‚åˆ", "ä¸é€‚åˆ", "ä¼˜ç¼ºç‚¹", "è¦ä¸è¦", "vs", "å¯¹æ¯”", "å…ˆçœ‹"],  # å†³ç­–æ¡†æ¶
    ]
    return sum(1 for kws in groups if any(k in hook for k in kws))


def _hook_valid(hook: str) -> bool:
    return bool(hook) and len(hook) <= 12 and _hook_elements_count(hook) >= 2


def _repair_hook(hook: str, title: str, angle: str, audience: str) -> str | None:
    try:
        prompt = (
            "æŠŠä¸‹é¢çš„ Hook æ”¹å†™æˆ <=12 å­—ï¼Œä¸”è‡³å°‘åŒ…å«ä»¥ä¸‹ 5 ç±»ä¸­çš„ 2 ç±»ï¼š"
            "åœ°ç‚¹èƒŒæ™¯/æ˜ç¡®æ”¶ç›Š/å¥½å¥‡è§¦å‘/æƒ…ç»ªè§¦å‘/å†³ç­–æ¡†æ¶ã€‚"
            "åªè¾“å‡ºä¸€è¡Œ Hookï¼Œä¸è¦ä»»ä½•è§£é‡Šã€‚\n"
            f"åŸæ ‡é¢˜: {title}\nè§’åº¦: {angle}\nç›®æ ‡äººç¾¤: {audience}\nåŸHook: {hook}"
        )
        resp = client.chat.completions.create(
            model=OPENAI_MODEL_NOTE,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯å°çº¢ä¹¦æ—…è¡Œæ–‡æ¡ˆç¼–è¾‘ï¼Œåªè¿”å›æœ€ç»ˆ Hook ä¸€è¡Œã€‚"},
                {"role": "user", "content": prompt},
            ],
            temperature=0.4,
            max_tokens=60,
        )
        fixed = (resp.choices[0].message.content or "").strip().splitlines()[0].strip()
        return fixed or None
    except Exception:
        log.exception("hook repair failed")
        return None


def _replace_hook(note_text: str, new_hook: str) -> str:
    lines = note_text.splitlines()
    idx, _ = _extract_hook_line(note_text)
    if idx is None:
        return note_text
    lines[idx] = new_hook
    return "\n".join(lines)


def _extract_json(text: str) -> str:
    s = (text or "").strip()
    if s.startswith("```"):
        lines = s.splitlines()
        if lines and lines[0].strip().startswith("```"):
            lines = lines[1:]
        if lines and lines[-1].strip() == "```":
            lines = lines[:-1]
        s = "\n".join(lines).strip()
    return s


def _wins_default() -> dict[str, Any]:
    return {
        "version": 1,
        "updated_at": datetime.now(tzinfo).isoformat(),
        "items": [],
    }


def _persist_wins_doc(doc: dict[str, Any]) -> bool:
    data_dir = WINS_FILE.parent
    if not data_dir.exists():
        log.error("Wins volume is not mounted: %s", data_dir)
        return False
    doc["updated_at"] = datetime.now(tzinfo).isoformat()
    data_dir.mkdir(parents=True, exist_ok=True)
    tmp_file = WINS_FILE.with_name(f"{WINS_FILE.name}.tmp")
    tmp_file.write_text(json.dumps(doc, ensure_ascii=False, indent=2), encoding="utf-8")
    tmp_file.replace(WINS_FILE)
    return True


def load_wins() -> tuple[list[dict], str | None]:
    data_dir = WINS_FILE.parent
    if not data_dir.exists():
        log.error("Wins volume is not mounted: %s", data_dir)
        return [], "âš ï¸ /data æœªæŒ‚è½½ï¼Œå·²è·³è¿‡çˆ†æ¬¾å­¦ä¹ ã€‚"

    if not WINS_FILE.exists():
        _persist_wins_doc(_wins_default())
        return [], None

    try:
        doc = json.loads(WINS_FILE.read_text(encoding="utf-8"))
        items = doc.get("items") if isinstance(doc, dict) else []
        if not isinstance(items, list):
            raise ValueError("wins items is not list")
        return items, None
    except Exception:
        log.exception("wins.json corrupted, backing up and resetting")
        ts = datetime.now(tzinfo).strftime("%Y%m%d_%H%M%S")
        bak = WINS_FILE.with_name(f"wins.json.bak.{ts}")
        try:
            if WINS_FILE.exists():
                WINS_FILE.replace(bak)
        except Exception:
            log.exception("failed to backup corrupted wins file")
        _persist_wins_doc(_wins_default())
        return [], f"âš ï¸ wins.json å·²æŸåï¼Œå·²å¤‡ä»½ä¸º {bak.name} å¹¶é‡ç½®ã€‚"


def append_win(item: dict[str, Any]) -> tuple[bool, str | None]:
    wins, warning = load_wins()
    doc = _wins_default()
    doc["items"] = wins
    doc["items"].append(item)
    ok = _persist_wins_doc(doc)
    return ok, warning


def summarize_wins(wins: list[dict]) -> str:
    recent = wins[-30:]
    if not recent:
        return "- æœ€è¿‘çˆ†æ¬¾ç»“æ„ï¼šæš‚æ— æ ·æœ¬\n- é«˜é¢‘å…ƒç´ ï¼šä¼˜å…ˆæµ‹è¯• RMé¢„ç®— + å‘¨æœ«/2å¤©1å¤œ\n- å»ºè®®å»¶ä¼¸ï¼š1) æœ¬åœ°ä½é¢„ç®— 2) äº¤é€šé¿å‘ 3) èŠ±è´¹æ‹†è§£ 4) æ¸…å•æ¨¡æ¿ 5) å†·é—¨çŸ­é€”"

    texts = []
    for w in recent:
        texts.append(" ".join([
            str(w.get("title") or ""),
            str(w.get("notes") or ""),
            " ".join(w.get("tags") or []),
        ]))
    merged = " ".join(texts)

    rm_hits = re.findall(r"RM\s*\d+", merged, flags=re.IGNORECASE)
    places = [k for k in ["KL", "é›ªå…°èª", "Selangor", "æ§ŸåŸ", "Penang", "æ€¡ä¿", "Ipoh", "é©¬å…­ç”²", "Melaka"] if re.search(re.escape(k), merged, flags=re.IGNORECASE)]
    topics = [k for k in ["2D1N", "3D2N", "å‘¨æœ«", "staycation", "æ£®æ—", "å†·é—¨", "é¿å‘", "èŠ±è´¹æ‹†è§£", "æ¸…å•"] if re.search(re.escape(k), merged, flags=re.IGNORECASE)]

    rm_top = "/".join(rm_hits[:3]) if rm_hits else "RMé¢„ç®—"
    place_top = "ã€".join(places[:4]) if places else "KL/é›ªå…°èª"
    topic_top = "ã€".join(topics[:6]) if topics else "å‘¨æœ«ã€é¿å‘ã€èŠ±è´¹æ‹†è§£"

    return (
        f"- æœ€è¿‘çˆ†æ¬¾ç»“æ„ï¼šä»¥æœ¬åœ°çŸ­é€” + å…·ä½“é¢„ç®—åˆ‡å…¥ï¼Œå¸¸è§é‡‘é¢é”šç‚¹ {rm_top}ã€‚\n"
        f"- é«˜é¢‘å…ƒç´ ï¼šåœ°åŒº {place_top}ï¼›é¢˜æ {topic_top}ã€‚\n"
        "- å»ºè®®å»¶ä¼¸ï¼š1) RM100-300å‘¨æœ«è·¯çº¿ 2) 2å¤©1å¤œäº¤é€šç»„åˆ 3) é…’åº—/æ™¯ç‚¹é¿å‘ 4) èŠ±è´¹æ‹†è§£æ¨¡æ¿ 5) å†·é—¨æ£®æ—staycation"
    )


def _parse_win_command(text: str) -> tuple[dict[str, Any] | None, str | None]:
    payload = (text or "").strip()
    try:
        parts = shlex.split(payload)
    except Exception:
        return None, "âŒ å‚æ•°è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥å¼•å·ã€‚"
    if not parts or not parts[0].startswith("/win"):
        return None, "âŒ ç”¨æ³•ï¼š/win <url> saves= likes= comments= follows= title=\"...\" note=\"...\" tags=a,b"
    if len(parts) < 2 or not parts[1].startswith("http"):
        return None, "âŒ è¯·æä¾›æœ‰æ•ˆé“¾æ¥ï¼š/win <url> ..."

    data: dict[str, Any] = {
        "source": "xhs",
        "url": parts[1],
        "title": "",
        "notes": "",
        "metrics": {"saves": None, "likes": None, "comments": None, "follows": None},
        "tags": [],
        "region_focus": "MY_LOCAL",
    }

    for p in parts[2:]:
        if "=" not in p:
            continue
        k, v = p.split("=", 1)
        key = k.strip().lower()
        val = v.strip().strip('"').strip("'")
        if key in ("saves", "likes", "comments", "follows"):
            data["metrics"][key] = int(val) if val.isdigit() else None
        elif key == "title":
            data["title"] = val
        elif key in ("note", "notes"):
            data["notes"] = val
        elif key == "tags":
            data["tags"] = [x.strip() for x in val.split(",") if x.strip()]

    now = datetime.now(tzinfo)
    rand4 = "".join(random.choices(string.ascii_uppercase + string.digits, k=4))
    data["id"] = f"win_{now.strftime('%Y%m%d_%H%M%S')}_{rand4}"
    data["created_at"] = now.isoformat()
    return data, None


def _is_admin_user(user_id: int | None) -> bool:
    return bool(user_id and ADMIN_IDS and user_id in ADMIN_IDS)


async def summarize_script_for_learning(text: str) -> dict:
    resp = client.chat.completions.create(
        model=OPENAI_MODEL_NOTE,
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ—…è¡Œå†…å®¹ç»“æ„åˆ†æå¼•æ“ã€‚ä½ ä¸ä¼šæ”¹å†™å†…å®¹ï¼Œåªæç‚¼ç»“æ„æ¨¡å¼ã€‚"},
            {
                "role": "user",
                "content": (
                    "åˆ†æä»¥ä¸‹å°çº¢ä¹¦æ—…è¡Œè„šæœ¬ï¼Œæç‚¼ï¼š\n"
                    "1) æ ‡é¢˜ç»“æ„å…¬å¼\n"
                    "2) Hookç±»å‹\n"
                    "3) å†³ç­–æ¡†æ¶\n"
                    "4) æƒ…ç»ªè§¦å‘ç‚¹\n"
                    "5) å¯å¤ç”¨ä¿¡æ¯ç»“æ„\n"
                    "6) 5ä¸ªå»¶ä¼¸è§’åº¦\n"
                    "è¿”å›JSONå¯¹è±¡ï¼š\n"
                    "{\n"
                    " 'title_formula': '',\n"
                    " 'hook_type': '',\n"
                    " 'decision_frame': '',\n"
                    " 'emotional_trigger': '',\n"
                    " 'info_pattern': '',\n"
                    " 'topic_cluster': []\n"
                    "}\n\n"
                    f"è„šæœ¬æ–‡æœ¬ï¼š\n{text}"
                ),
            },
        ],
        response_format={"type": "json_object"},
        temperature=0.2,
        max_tokens=600,
    )
    content = (resp.choices[0].message.content or "{}").strip()
    data = json.loads(_extract_json(content))
    return data if isinstance(data, dict) else {}


def _parse_wintext_message(text: str) -> tuple[dict[str, int], str]:
    raw = (text or "").strip()
    if not raw:
        return {}, ""
    lines = raw.splitlines()
    first = lines[0].strip()
    body = "\n".join(lines[1:]).strip() if len(lines) > 1 else ""

    metrics: dict[str, int] = {}
    for key in ("saves", "likes", "comments", "follows"):
        m = re.search(rf"{key}\s*=\s*(\d+)", first, flags=re.IGNORECASE)
        if m:
            metrics[key] = int(m.group(1))

    if not body:
        if first.startswith("/wintext"):
            body = first[len("/wintext"):].strip()
        else:
            body = first
    return metrics, body


async def generate_note(title: str, angle: str, audience: str) -> tuple[str, bool]:
    skill_pairs = load_skill_texts(str(SKILLS_DIR))
    system_skills, context_skills = _build_skill_sections(skill_pairs)
    system_text = NOTE_SYSTEM
    if system_skills:
        system_text = f"{NOTE_SYSTEM}\n\n{system_skills}" if NOTE_SYSTEM else system_skills
    user_prompt = build_note_user_prompt(title, angle, audience)
    if context_skills:
        user_prompt = f"{user_prompt}\n\nã€å‚è€ƒè®°å¿†ï¼Œä»…ä¾›å‚è€ƒã€‘\n{context_skills}"
    resp = client.chat.completions.create(
        model=OPENAI_MODEL_NOTE,
        messages=[
            {"role": "system", "content": system_text},
            {"role": "user", "content": user_prompt},
        ],
        temperature=0.7,
        max_tokens=NOTE_MAX_TOKENS,
    )
    note_text = (resp.choices[0].message.content or "").strip()
    idx, hook = _extract_hook_line(note_text)
    needs_warning = False
    if idx is not None and not _hook_valid(hook):
        repaired = _repair_hook(hook, title, angle, audience)
        if repaired and _hook_valid(repaired):
            note_text = _replace_hook(note_text, repaired)
        else:
            needs_warning = True
    return note_text, needs_warning


def score_item(item: dict) -> dict:
    """
    Simple deterministic-ish scoring (0-40).
    """
    title = (item.get("title") or "").lower()
    angle = (item.get("angle") or "").lower()
    audience = (item.get("target_audience") or "").lower()

    def has_any(s: str, kws: list[str]) -> bool:
        return any(k in s for k in kws)

    save_score = 0
    follow_score = 0
    clarity_score = 0
    exec_score = 0

    # Save potential
    if has_any(title, ["é¿å‘", "å‘", "æ¸…å•", "checklist", "åˆ«", "ä¸è¦", "æ”»ç•¥", "çœ", "rm", "é¢„ç®—", "èŠ±è´¹", "cost"]):
        save_score += 6
    if any(ch.isdigit() for ch in title):
        save_score += 2
    if has_any(title, ["å¯¹æ¯”", "vs", "æ¯”è¾ƒ"]):
        save_score += 2

    # Follow potential (series vibe / audience clarity)
    if has_any(audience, ["æ–°æ‰‹", "ç¬¬ä¸€æ¬¡", "æ‡’äºº", "budget", "ç©·æ¸¸", "äº²å­", "æƒ…ä¾£", "ä¸Šç­æ—", "ç‹¬æ—…", "å°ç™½"]):
        follow_score += 5
    if has_any(title, ["ç³»åˆ—", "ç¬¬", "part", "åˆé›†"]):
        follow_score += 3
    if has_any(angle, ["ç³»åˆ—", "æ¨¡æ¿", "æ¡†æ¶"]):
        follow_score += 2

    # Clarity
    if len(title) <= 28:
        clarity_score += 5
    if has_any(title, ["æ€ä¹ˆ", "å¦‚ä½•", "3", "5", "7", "10", "ç§’", "åˆ†é’Ÿ", "å°æ—¶", "rm", "usd"]):
        clarity_score += 5

    # Execution (actionable)
    if has_any(angle, ["æ­¥éª¤", "step", "æ¸…å•", "æ¨¡æ¿", "æµç¨‹", "ç­–ç•¥", "é¢„è®¢", "booking", "æœºåœº", "éª—å±€", "scam"]):
        exec_score += 6
    if has_any(title, ["å‡†å¤‡", "å¸¦ä»€ä¹ˆ", "ä¹°ä»€ä¹ˆ", "ç”¨ä»€ä¹ˆ", "è®¢"]):
        exec_score += 4

    has_local = has_any(title + " " + angle + " " + audience, MY_LOCAL_KEYWORDS)
    has_budget_or_duration = has_any(title + " " + angle, ["rm", "å‘¨æœ«", "2å¤©1å¤œ", "1å¤©", "2d1n", "3d2n"])
    has_overseas = has_any(title + " " + angle + " " + audience, [x.lower() for x in OVERSEAS_KEYWORDS])

    if has_overseas:
        return {
            "save": 0,
            "follow": 0,
            "clarity": 0,
            "exec": 0,
            "total": 0,
        }

    local_bonus = 0
    if has_local and has_any(title + " " + angle, ["rm"]):
        local_bonus += 6
    elif has_local and has_budget_or_duration:
        local_bonus += 4
    elif has_local:
        local_bonus += 2

    # cap each to 0-10
    save_score = min(save_score, 10)
    follow_score = min(follow_score, 10)
    clarity_score = min(clarity_score, 10)
    exec_score = min(exec_score, 10)

    total = save_score + follow_score + clarity_score + exec_score + local_bonus
    return {
        "save": save_score,
        "follow": follow_score,
        "clarity": clarity_score,
        "exec": exec_score,
        "total": total,
    }


async def generate_6_titles(app: Application | None = None) -> list[dict]:
    skill_pairs = load_skill_texts(str(SKILLS_DIR))
    system_skills, context_skills = _build_skill_sections(skill_pairs)
    wins, warning = load_wins()
    if warning:
        log.warning(warning)
        if app:
            try:
                await app.bot.send_message(chat_id=APPROVAL_CHAT_ID, text=warning)
            except Exception:
                log.exception("failed to send wins warning")
    dynamic_prompt = (
        TITLE_PROMPT
        + "\n\nã€è¿‘æœŸçˆ†æ¬¾å­¦ä¹ æ‘˜è¦ã€‘\n"
        + summarize_wins(wins)
        + "\n\nè¯·ä¸¥æ ¼æŒ‰æœ¬åœ°æ—…è¡Œç­–ç•¥å‡ºé¢˜ã€‚"
    )
    if context_skills:
        dynamic_prompt = f"{dynamic_prompt}\n\nã€å‚è€ƒè®°å¿†ï¼Œä»…ä¾›å‚è€ƒã€‘\n{context_skills}"

    system_text = "ä½ æ˜¯ä¸€ä¸ªå°çº¢ä¹¦æ—…è¡Œå¢é•¿å¼•æ“ã€‚"
    if system_skills:
        system_text = f"{system_text}\n\n{system_skills}"
    resp = client.chat.completions.create(
        model=MODEL_TITLES,
        messages=[
            {
                "role": "system",
                "content": system_text,
            },
            {
                "role": "system",
                "content": "å…¨éƒ¨è¾“å‡ºå¿…é¡»ä¸ºä¸­æ–‡ï¼ˆå°çº¢ä¹¦è¯­å¢ƒï¼‰ã€‚åªè¾“å‡ºJSONï¼Œä¸è¦ä»£ç å—ã€‚"
            },
            {
                "role": "user",
                "content": dynamic_prompt
            },
        ],
        response_format={"type": "json_object"},
        temperature=0.8,
        max_tokens=900,
    )
    content = resp.choices[0].message.content or "{}"
    try:
        data = json.loads(content)
    except Exception:
        data = json.loads(_extract_json(content))
    try:
        items = data.get("items") if isinstance(data, dict) else None
        if not isinstance(items, list) or len(items) != 6:
            raise ValueError("Not 6 items")
        return items
    except Exception as e:
        log.error("JSON parse failed: %s | raw=%s", e, content[:5000])
        raise


def _get_regions_pool() -> list[str]:
    raw = (os.getenv("REGIONS_POOL", "") or "").strip()
    if not raw:
        return DEFAULT_REGIONS_POOL
    vals = [x.strip().lower() for x in raw.split(",") if x.strip()]
    return vals if len(vals) >= 2 else DEFAULT_REGIONS_POOL


def _pick_regions_for_day(now: datetime) -> tuple[str, str]:
    regions = _get_regions_pool()
    idx = (now.timetuple().tm_yday * 2) % len(regions)
    return regions[idx], regions[(idx + 1) % len(regions)]


async def generate_5_title_candidates(region_a: str, region_b: str) -> list[dict]:
    prompt = (
        "ä½ æ˜¯å°çº¢ä¹¦é©¬æ¥è¥¿äºšæ—…è¡Œæ ‡é¢˜ç¼–è¾‘ã€‚\n"
        "è¾“å‡º5æ¡æ ‡é¢˜å€™é€‰ï¼Œå¿…é¡»è¦†ç›–ä¸¤ä¸ªåœ°åŒºã€‚\n"
        f"ä»Šæ—¥åœ°åŒº: {region_a}, {region_b}\n"
        "ç¡¬æ€§è¦æ±‚:\n"
        "1) ä»…è¾“å‡ºJSONï¼Œæ ¼å¼ä¸º {\"items\":[...]}ã€‚\n"
        "2) itemsé•¿åº¦å¿…é¡»ä¸º5ã€‚\n"
        "3) æ¯æ¡å¿…é¡»åŒ…å«ä¸”ä»…åŒ…å«: title, region, location_hintã€‚\n"
        "4) regionå¿…é¡»ä¸¥æ ¼ç­‰äºä»Šæ—¥åœ°åŒºä¹‹ä¸€ã€‚\n"
        "5) æ¯æ¡æ ‡é¢˜14-18ä¸ªä¸­æ–‡å­—ç¬¦ã€‚\n"
        "6) æ¯æ¡æ ‡é¢˜å¿…é¡»åŒ…å«å¯æœç´¢çš„å…·ä½“åœ°ç‚¹åï¼Œä¸èƒ½åªå†™å·å/å¤§åŒºã€‚\n"
        "7) é£æ ¼é…æ¯”: ç¬¬ä¸€äººç§°2æ¡ã€ä»·æ ¼/å†²çª2æ¡ã€æ—¶é—´/æ¡ä»¶1æ¡ã€‚\n"
        "8) ç¦æ­¢æµ·å¤–ç›®çš„åœ°ã€‚"
    )

    banned_generic = {"å¥½å»å¤„", "æ”»ç•¥", "æ¨è", "å‘¨æœ«"}
    region_words = {region_a.lower(), region_b.lower(), "penang", "genting", "melaka", "selangor", "kl", "perak", "johor", "sabah"}

    def _validate_items(items: Any) -> tuple[bool, str]:
        if not isinstance(items, list) or len(items) != 5:
            return False, "items must be list of 5"
        seen_regions = set()
        location_signal_fails = 0
        for i, it in enumerate(items, start=1):
            if not isinstance(it, dict):
                return False, f"item#{i} must be object"
            title = str(it.get("title", "")).strip()
            region = str(it.get("region", "")).strip().lower()
            location_hint = str(it.get("location_hint", "")).strip()
            if not title or not region or not location_hint:
                return False, f"item#{i} has empty fields"
            cjk_chars = re.findall(r"[\u4e00-\u9fff]", title)
            cjk_len = len(cjk_chars)
            latin_tokens = re.findall(r"[A-Za-z0-9]+", title)
            bonus = 2 if latin_tokens else 0
            effective_len = cjk_len + bonus
            if effective_len < 14 or effective_len > 18:
                return False, f"item#{i} title length out of range"
            location_keywords = ["Hotel", "Resort", "Cabin", "Airbnb", "Forest", "Villa", "Homestay"]
            has_upper_word = bool(re.search(r"\b[A-Z][a-zA-Z]+\b", title))
            has_location_kw = any(k in title for k in location_keywords)
            if not has_upper_word and not has_location_kw:
                location_signal_fails += 1
            if region not in {region_a, region_b}:
                return False, f"item#{i} region invalid"
            if len(location_hint) < 2 or location_hint.lower() == region:
                return False, f"item#{i} location_hint too generic"
            if any(b in title for b in banned_generic):
                return False, f"item#{i} title contains banned generic phrase"
            compact = re.sub(r"[\s/ã€ï¼Œ,ã€‚.!ï¼?ï¼Ÿ\-]+", "", title).lower()
            if compact in region_words:
                return False, f"item#{i} title is generic region word"
            seen_regions.add(region)
        if location_signal_fails > 1:
            return False, "too many items lack concrete location signal"
        if region_a not in seen_regions or region_b not in seen_regions:
            return False, "items do not cover both regions"
        return True, "ok"

    last_err = ""
    for _ in range(3):
        resp = client.chat.completions.create(
            model=MODEL_TITLES,
            messages=[
                {"role": "system", "content": "ä½ åªè¿”å›åˆæ³•JSONå¯¹è±¡ï¼Œä¸è¦ä»£ç å—ï¼Œä¸è¦è§£é‡Šã€‚"},
                {"role": "user", "content": prompt},
            ],
            response_format={"type": "json_object"},
            temperature=0.6,
            max_tokens=700,
        )
        content = (resp.choices[0].message.content or "{}").strip()
        try:
            data = json.loads(_extract_json(content))
        except Exception:
            last_err = "invalid JSON"
            continue
        items = data.get("items") if isinstance(data, dict) else None
        ok, reason = _validate_items(items)
        if ok:
            return items
        last_err = reason

    raise ValueError(f"title candidates validation failed after retries: {last_err}")


def format_titles_message(content_id: str, regions: list[str], items: list[dict]) -> str:
    lines = [
        "ğŸ“Œ ä»Šæ—¥ 5 æ¡æ ‡é¢˜å€™é€‰ï¼ˆå¾…é€‰æ‹©ï¼‰",
        f"ğŸ†” content_id: {content_id}",
        f"ğŸŒ åŒºåŸŸè½®æ¢: {regions[0]} / {regions[1]}",
        "",
    ]
    for i, it in enumerate(items, start=1):
        lines.append(f"{i}. {it.get('title','').strip()}")
    return "\n".join(lines).strip()


def approval_keyboard(content_id: str) -> InlineKeyboardMarkup:
    kb = [
        [
            InlineKeyboardButton("âœ… é€‰ 1", callback_data=f"pick:1:{content_id}"),
            InlineKeyboardButton("âœ… é€‰ 2", callback_data=f"pick:2:{content_id}"),
            InlineKeyboardButton("âœ… é€‰ 3", callback_data=f"pick:3:{content_id}"),
        ],
        [
            InlineKeyboardButton("âœ… é€‰ 4", callback_data=f"pick:4:{content_id}"),
            InlineKeyboardButton("âœ… é€‰ 5", callback_data=f"pick:5:{content_id}"),
        ],
        [
            InlineKeyboardButton("ğŸ§¾ ç”Ÿæˆè„šæœ¬", callback_data=f"generate:{content_id}"),
            InlineKeyboardButton("ğŸ§¹ æ¸…ç©ºé€‰æ‹©", callback_data=f"clear:{content_id}"),
        ],
        [
            InlineKeyboardButton("ğŸ” é‡ç”Ÿæˆ", callback_data=f"regen:{content_id}"),
        ],
    ]
    return InlineKeyboardMarkup(kb)


def build_script_prompt(title: str, region: str, location_hint: str, loaded_skill_texts: list[tuple[str, str]]) -> str:
    skill_blocks = []
    for name, text in loaded_skill_texts:
        skill_blocks.append(f"[RULES FILE: {name}]\n{text}")
    skills_text = "\n\n".join(skill_blocks)
    return (
        "è¯·ç”Ÿæˆ1æ¡å®Œæ•´å°çº¢ä¹¦æ—…è¡Œè„šæœ¬ã€‚ä¸¥æ ¼æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼Œæ ‡é¢˜å’Œé¡ºåºä¸èƒ½å˜ï¼š\n\n"
        "ğŸ¬ POST SCRIPT\n"
        "Hook\n"
        "<...>\n\n"
        "æ­£æ–‡\n"
        "<...>\n\n"
        "Save trigger\n"
        "<...>\n\n"
        "âœï¸ CAPTION\n"
        "<...>\n\n"
        "ğŸ· HASHTAGS\n"
        "<...>\n\n"
        "ğŸ’¡ VISUAL SHOTLIST\n"
        "- Shot 1:\n"
        "- Shot 2:\n"
        "- Shot 3:\n"
        "- Shot 4:\n"
        "- Shot 5:\n\n"
        "ç¡¬æ€§è§„åˆ™:\n"
        "- ä¸­æ–‡ä¸ºä¸»ï¼Œå¯å°‘é‡è‡ªç„¶MYå£å»è¯ï¼ˆeh/tight/chill/menu/localï¼‰ï¼Œä¸å¯è¿ç»­è‹±æ–‡é‡å¥ã€‚\n"
        "- å¿…é¡»ç¬¬ä¸€äººç§°çœŸå®è¸©ç‚¹æ„Ÿï¼Œä¸è¦å‡ºç°ï¼šç¬¬ä¸€/å…¶æ¬¡/æ€»ç»“/ä»Šå¤©æ¥åˆ†äº«/å¾ˆå¤šäººé—®æˆ‘ã€‚\n"
        "- å¿…é¡»å‡ºç°1ä¸ªå…·ä½“åœ°ç‚¹ï¼ˆä¼˜å…ˆä½¿ç”¨location_hintï¼‰ã€3ä¸ªå¯æ‹ç»†èŠ‚ã€1ä¸ªäººç‰©å…ƒç´ ã€‚\n"
        "- ç»“å°¾å¿…é¡»ç•¥å¸¦ä¸å®Œç¾ï¼ˆå¦‚ tight/æ²¡æœ‰å¾ˆçˆ½/ä¸è¦expectå¤ªå¤šï¼‰ã€‚\n"
        f"- é¢˜ç›®: {title}\n"
        f"- region: {region}\n"
        f"- location_hint: {location_hint}\n\n"
        f"å‚è€ƒè§„åˆ™:\n{skills_text}"
    )


def _split_script_for_telegram(script_text: str, limit: int = 3500) -> list[str]:
    sections = [x for x in re.split(r"\n(?=ğŸ¬ POST SCRIPT|âœï¸ CAPTION|ğŸ· HASHTAGS|ğŸ’¡ VISUAL SHOTLIST)", script_text.strip()) if x]
    if not sections:
        return [script_text]
    chunks: list[str] = []
    cur = ""
    for sec in sections:
        candidate = sec if not cur else f"{cur}\n\n{sec}"
        if len(candidate) <= limit:
            cur = candidate
        else:
            if cur:
                chunks.append(cur)
            if len(sec) <= limit:
                cur = sec
            else:
                sec_lines = sec.splitlines()
                if not sec_lines:
                    continue
                head = sec_lines[0]
                body = sec_lines[1:]
                part = head
                for line in body:
                    cand = f"{part}\n{line}" if part else line
                    if len(cand) <= limit:
                        part = cand
                    else:
                        chunks.append(part)
                        part = f"{head}\n{line}" if len(f"{head}\n{line}") <= limit else line[:limit]
                if part:
                    cur = part
    if cur:
        chunks.append(cur)
    return chunks


async def _generate_selected_scripts(app: Application, content_id: str, draft: dict[str, Any]) -> None:
    selected = draft.get("selected") or []
    if len(selected) < 2:
        return
    if draft.get("status") == "generated":
        return
    skill_pairs = load_skill_texts(str(SKILLS_DIR))
    scripts = draft.setdefault("scripts", {})
    for idx in selected[:2]:
        if str(idx) in scripts:
            continue
        item = draft["items"][idx - 1]
        prompt = build_script_prompt(
            item.get("title", "").strip(),
            item.get("region", "").strip(),
            item.get("location_hint", "").strip(),
            skill_pairs,
        )
        resp = client.chat.completions.create(
            model=OPENAI_MODEL_SCRIPT,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯å°çº¢ä¹¦æ—…è¡Œè„šæœ¬ç¼–è¾‘ã€‚ä¸¥æ ¼æŒ‰ç”¨æˆ·ç»™å®šæ ¼å¼è¾“å‡ºã€‚"},
                {"role": "user", "content": prompt},
            ],
            temperature=0.7,
            max_tokens=1600,
        )
        script_text = (resp.choices[0].message.content or "").strip()
        scripts[str(idx)] = script_text
        header = f"ğŸ§¾ è„šæœ¬ #{idx} | {item.get('title','').strip()}"
        chunks = _split_script_for_telegram(script_text)
        if chunks:
            chunks[0] = f"{header}\n\n{chunks[0]}"
        for ch in chunks:
            await app.bot.send_message(chat_id=APPROVAL_CHAT_ID, text=ch, disable_web_page_preview=True)
    draft["status"] = "generated"


async def run_daily_job(app: Application) -> None:
    now = datetime.now(tzinfo)
    content_id = make_content_id(now)
    log.info("Running daily job content_id=%s", content_id)
    region_a, region_b = _pick_regions_for_day(now)
    try:
        items = await generate_5_title_candidates(region_a, region_b)
    except Exception:
        log.exception("daily title generation failed content_id=%s", content_id)
        await app.bot.send_message(chat_id=APPROVAL_CHAT_ID, text="âŒ ä»Šæ—¥æ ‡é¢˜ç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚")
        return

    msg = format_titles_message(content_id, [region_a, region_b], items)
    await app.bot.send_message(chat_id=APPROVAL_CHAT_ID, text=msg, reply_markup=approval_keyboard(content_id), disable_web_page_preview=True)

    app.bot_data.setdefault("drafts", {})[content_id] = {
        "created_at": now.isoformat(),
        "regions": [region_a, region_b],
        "items": items,
        "selected": [],
        "scripts": {},
        "status": "pending",
    }


async def cb_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    q = update.callback_query
    if not q:
        return
    await q.answer()

    data = q.data or ""
    parts = data.split(":")
    if len(parts) < 2:
        log.warning("Malformed callback data: %s", data)
        return

    drafts = context.application.bot_data.setdefault("drafts", {})
    action = parts[0]

    if action == "pick":
        if len(parts) < 3:
            await q.edit_message_text("âŒ æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·é‡è¯•ã€‚")
            return
        try:
            pick_idx = int(parts[1])
        except Exception:
            await q.edit_message_text("âŒ é€‰æ‹©åºå·æ— æ•ˆï¼Œè¯·é‡è¯•ã€‚")
            return
        if pick_idx < 1 or pick_idx > 5:
            await q.edit_message_text("âŒ é€‰æ‹©åºå·æ— æ•ˆï¼Œè¯·é‡è¯•ã€‚")
            return
        content_id = parts[2]
        d = drafts.get(content_id)
        if not d:
            await q.edit_message_text("âŒ æ‰¾ä¸åˆ°è¯¥ content_idï¼ˆå¯èƒ½é‡å¯åä¸¢å¤±ï¼‰ã€‚è¯·ç‚¹ ğŸ” é‡ç”Ÿæˆã€‚")
            return
        selected = d.setdefault("selected", [])

        if pick_idx in selected:
            selected.remove(pick_idx)
            selected.sort()
            d["status"] = "pending"
            await q.edit_message_text(
                format_titles_message(content_id, d.get("regions", ["-", "-"]), d.get("items", []))
                + f"\n\nâœ… å·²é€‰æ‹©: {selected}",
                reply_markup=approval_keyboard(content_id),
                disable_web_page_preview=True,
            )
            return

        if len(selected) >= 2:
            await q.edit_message_text(
                format_titles_message(content_id, d.get("regions", ["-", "-"]), d.get("items", []))
                + f"\n\nâš ï¸ å·²é€‰æ»¡2æ¡ï¼š{selected[:2]}ï¼Œç‚¹ ğŸ§¾ ç”Ÿæˆè„šæœ¬ æˆ– ğŸ” é‡ç”Ÿæˆ",
                reply_markup=approval_keyboard(content_id),
                disable_web_page_preview=True,
            )
            return

        selected.append(pick_idx)
        selected.sort()

        if len(selected) >= 2:
            try:
                await _generate_selected_scripts(context.application, content_id, d)
                await q.edit_message_text(
                    format_titles_message(content_id, d.get("regions", ["-", "-"]), d.get("items", []))
                    + f"\n\nâœ… å·²é€‰æ‹©: {selected[:2]}ï¼Œè„šæœ¬å·²ç”Ÿæˆã€‚",
                    reply_markup=approval_keyboard(content_id),
                    disable_web_page_preview=True,
                )
            except Exception:
                log.exception("script generation failed content_id=%s", content_id)
                await context.application.bot.send_message(chat_id=APPROVAL_CHAT_ID, text="âŒ è„šæœ¬ç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åå†è¯•ã€‚")
        else:
            await q.edit_message_text(
                format_titles_message(content_id, d.get("regions", ["-", "-"]), d.get("items", []))
                + f"\n\nâœ… å·²é€‰æ‹©: {selected}ï¼ˆå†é€‰1æ¡åè‡ªåŠ¨ç”Ÿæˆè„šæœ¬ï¼‰",
                reply_markup=approval_keyboard(content_id),
                disable_web_page_preview=True,
            )
        return

    if action == "generate":
        content_id = parts[1] if len(parts) >= 2 else ""
        d = drafts.get(content_id)
        if not d:
            await q.edit_message_text("âŒ æ‰¾ä¸åˆ°è¯¥ content_idï¼ˆå¯èƒ½é‡å¯åä¸¢å¤±ï¼‰ã€‚è¯·ç‚¹ ğŸ” é‡ç”Ÿæˆã€‚")
            return
        if len(d.get("selected", [])) < 2:
            await q.edit_message_text(
                format_titles_message(content_id, d.get("regions", ["-", "-"]), d.get("items", []))
                + f"\n\nâš ï¸ å½“å‰ä»…é€‰ä¸­ {len(d.get('selected', []))} æ¡ï¼Œè¯·å…ˆé€‰æ»¡2æ¡ã€‚",
                reply_markup=approval_keyboard(content_id),
                disable_web_page_preview=True,
            )
            return
        try:
            await _generate_selected_scripts(context.application, content_id, d)
            await q.edit_message_text(
                format_titles_message(content_id, d.get("regions", ["-", "-"]), d.get("items", []))
                + f"\n\nâœ… å·²é€‰æ‹©: {d.get('selected', [])[:2]}ï¼Œè„šæœ¬å·²ç”Ÿæˆã€‚",
                reply_markup=approval_keyboard(content_id),
                disable_web_page_preview=True,
            )
        except Exception:
            log.exception("manual generate failed")
            await context.application.bot.send_message(chat_id=APPROVAL_CHAT_ID, text="âŒ è„šæœ¬ç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åå†è¯•ã€‚")
        return

    if action == "clear":
        content_id = parts[1] if len(parts) >= 2 else ""
        d = drafts.get(content_id)
        if not d:
            await q.edit_message_text("âŒ æ‰¾ä¸åˆ°è¯¥ content_idï¼ˆå¯èƒ½é‡å¯åä¸¢å¤±ï¼‰ã€‚è¯·ç‚¹ ğŸ” é‡ç”Ÿæˆã€‚")
            return
        d["selected"] = []
        d["status"] = "pending"
        await q.edit_message_text(
            format_titles_message(content_id, d.get("regions", ["-", "-"]), d.get("items", [])) + "\n\nâœ… å·²æ¸…ç©ºé€‰æ‹©ã€‚",
            reply_markup=approval_keyboard(content_id),
            disable_web_page_preview=True,
        )
        return

    if action == "regen":
        content_id = parts[1] if len(parts) >= 2 else ""
        try:
            now = datetime.now(tzinfo)
            old = drafts.get(content_id) or {}
            regions = old.get("regions") if isinstance(old.get("regions"), list) and len(old.get("regions")) >= 2 else list(_pick_regions_for_day(now))
            region_a, region_b = regions[0], regions[1]
            items = await generate_5_title_candidates(region_a, region_b)
            drafts[content_id] = {
                "created_at": now.isoformat(),
                "regions": [region_a, region_b],
                "items": items,
                "selected": [],
                "scripts": {},
                "status": "pending",
            }
            msg = format_titles_message(content_id, [region_a, region_b], items)
            await q.edit_message_text(msg, reply_markup=approval_keyboard(content_id), disable_web_page_preview=True)
        except Exception:
            log.exception("regen failed")
            await q.edit_message_text("âŒ é‡ç”Ÿæˆå¤±è´¥ï¼ˆOpenAI æˆ– JSON æ ¼å¼é”™è¯¯ï¼‰ã€‚å†ç‚¹ä¸€æ¬¡æˆ–çœ‹æ—¥å¿—ã€‚")
        return


async def whoami(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    chat = update.effective_chat
    user = update.effective_user
    await update.message.reply_text(
        f"chat_id={chat.id}\nchat_type={chat.type}\nuser={user.username or user.id}"
    )


async def win(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user
    if not ADMIN_IDS:
        await update.message.reply_text("âŒ è¯·å…ˆè®¾ç½® ADMIN_IDSã€‚")
        return
    if not _is_admin_user(user.id if user else None):
        await update.message.reply_text("âŒ æ— æƒé™ã€‚")
        return

    item, err = _parse_win_command(update.message.text or "")
    if err:
        await update.message.reply_text(err)
        return
    ok, warning = append_win(item)
    if warning:
        await update.message.reply_text(warning)
    if ok:
        await update.message.reply_text(f"âœ… å·²è®°å½•çˆ†æ¬¾æ ·æœ¬ï¼š{item['id']}")
    else:
        await update.message.reply_text("âŒ å†™å…¥å¤±è´¥ï¼šè¯·æ£€æŸ¥ /data volume æŒ‚è½½ã€‚")


async def wins(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user
    if not ADMIN_IDS:
        await update.message.reply_text("âŒ è¯·å…ˆè®¾ç½® ADMIN_IDSã€‚")
        return
    if not _is_admin_user(user.id if user else None):
        await update.message.reply_text("âŒ æ— æƒé™ã€‚")
        return

    items, warning = load_wins()
    if warning:
        await update.message.reply_text(warning)
    last10 = items[-10:]
    if not last10:
        await update.message.reply_text("æš‚æ— çˆ†æ¬¾æ ·æœ¬ã€‚")
        return
    lines = ["ğŸ“š æœ€è¿‘ 10 æ¡çˆ†æ¬¾æ ·æœ¬ï¼š"]
    for it in reversed(last10):
        m = it.get("metrics") or {}
        lines.append(
            f"â€¢ {it.get('id','-')}\n"
            f"  {it.get('url','')}\n"
            f"  saves={m.get('saves')} likes={m.get('likes')}\n"
            f"  note={it.get('notes','')[:60]}"
        )
    await update.message.reply_text("\n".join(lines), disable_web_page_preview=True)


async def wintext(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user
    if not ADMIN_IDS:
        await update.message.reply_text("âŒ è¯·å…ˆè®¾ç½® ADMIN_IDSã€‚")
        return
    if not _is_admin_user(user.id if user else None):
        await update.message.reply_text("âŒ æ— æƒé™ã€‚")
        return

    msg_text = update.message.text if update.message else ""
    metrics, script_text = _parse_wintext_message(msg_text or "")
    if len(script_text) < 200:
        await update.message.reply_text("âŒ è„šæœ¬æ–‡æœ¬è¿‡çŸ­ï¼Œè‡³å°‘éœ€è¦ 200 å­—ã€‚")
        return

    try:
        learning = await summarize_script_for_learning(script_text)
    except Exception:
        log.exception("wintext summarize failed")
        await update.message.reply_text("âŒ å­¦ä¹ å¤±è´¥ï¼šOpenAI è¯·æ±‚å¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•ã€‚")
        return

    now = datetime.now(tzinfo)
    rand4 = "".join(random.choices(string.ascii_uppercase + string.digits, k=4))
    item = {
        "id": f"win_{now.strftime('%Y%m%d_%H%M%S')}_{rand4}",
        "created_at": now.isoformat(),
        "source": "manual_script",
        "raw_length": len(script_text),
        "metrics": metrics,
        "learning": learning,
    }
    ok, warning = append_win(item)
    if warning:
        await update.message.reply_text(warning)
    if not ok:
        await update.message.reply_text("âŒ å†™å…¥å¤±è´¥ï¼šè¯·æ£€æŸ¥ /data volume æŒ‚è½½ã€‚")
        return

    items, _ = load_wins()
    title_formula = str((learning or {}).get("title_formula") or "-")
    topic_cluster = (learning or {}).get("topic_cluster") or []
    if not isinstance(topic_cluster, list):
        topic_cluster = []
    topic_text = "ã€".join(str(x) for x in topic_cluster[:5]) if topic_cluster else "-"
    await update.message.reply_text(
        "âœ… å·²å­¦ä¹ ç»“æ„\n"
        f"æ ‡é¢˜å…¬å¼: {title_formula}\n"
        f"å»¶ä¼¸è§’åº¦: {topic_text}\n"
        f"å½“å‰ç´¯è®¡æ ·æœ¬: {len(items)} æ¡"
    )


async def learn_script(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    chat = update.effective_chat
    if not chat or chat.type not in ("group", "supergroup"):
        await update.message.reply_text("âŒ Please use /learn_script in the group.")
        return
    if ALLOWED_GROUP_CHAT_IDS and chat.id not in ALLOWED_GROUP_CHAT_IDS:
        await update.message.reply_text("âŒ This group is not allowed.")
        return

    msg_text = update.message.text if update.message else ""
    metadata, script_text = parse_learn_script_message(msg_text or "")
    if len(script_text) < 200:
        await update.message.reply_text("Need full script")
        return

    db_error = get_db_error()
    if db_error:
        await update.message.reply_text(db_error)
        return

    try:
        analysis = await asyncio.to_thread(analyze_script, client, script_text, metadata)
    except Exception:
        log.exception("learn_script analyze failed")
        await update.message.reply_text("OpenAI error: failed to analyze script")
        return

    try:
        tg = {
            "chat_id": int(chat.id),
            "user_id": int(update.effective_user.id) if update.effective_user else 0,
            "message_id": int(update.message.message_id) if update.message else 0,
        }
        store_result = await asyncio.to_thread(store_learning, metadata, analysis, script_text, tg)
    except Exception:
        log.exception("learn_script store failed")
        await update.message.reply_text("Storage error: failed to save learning")
        return

    hook_text = str(((analysis.get("hook") or {}).get("text") or "")).strip()
    platform = str(analysis.get("platform") or "other")
    content_type = str(analysis.get("content_type") or "other")
    script_hash = str(store_result.get("script_hash") or "")
    rules_processed = int(store_result.get("rules_processed") or 0)
    new_rules = int(store_result.get("new_rules") or 0)
    updated_rules = int(store_result.get("updated_rules") or 0)
    await update.message.reply_text(
        f"âœ… Learned & stored (MongoDB: {os.getenv('SKILLS_DB', 'xhs_travel').strip() or 'xhs_travel'})\n"
        f"platform/type: {platform}/{content_type}\n"
        f"hook: {hook_text}\n"
        f"rules processed: {rules_processed} (new: {new_rules}, updated: {updated_rules})\n"
        "db: xhs_skill_ingests, xhs_skill_rules, xhs_skill_logs\n"
        f"script_hash: {script_hash[:10]}"
    )


async def skill_audit(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    db_error = get_db_error()
    if db_error:
        await update.message.reply_text(db_error)
        return
    message = build_skill_audit_message()
    if not message:
        await update.message.reply_text("DB unavailable")
        return
    await update.message.reply_text(message)


def main() -> None:
    ensure_default_skill_files(str(SKILLS_DIR))
    if ping():
        ensure_indexes()
    else:
        log.warning("MongoDB ping failed at startup")
    app = Application.builder().token(TG_TOKEN).build()

    # commands / handlers
    app.add_handler(CommandHandler("whoami", whoami))
    app.add_handler(CommandHandler("win", win))
    app.add_handler(CommandHandler("wins", wins))
    app.add_handler(CommandHandler("wintext", wintext))
    app.add_handler(CommandHandler("learn_script", learn_script))
    app.add_handler(CommandHandler("skill_audit", skill_audit))
    app.add_handler(CallbackQueryHandler(cb_handler))

    # scheduler: 21:30 KL daily
    scheduler = AsyncIOScheduler(timezone=tzinfo)
    scheduler.add_job(
        run_daily_job,
        CronTrigger(hour=RUN_HOUR, minute=RUN_MIN, timezone=tzinfo),
        args=[app],        
        id="daily_titles",
        replace_existing=True,
        misfire_grace_time=300,
    )
    scheduler.start()

    log.info("Bot started. Daily schedule %02d:%02d %s", RUN_HOUR, RUN_MIN, TZ)
    app.run_polling(close_loop=False)


if __name__ == "__main__":
    main()
